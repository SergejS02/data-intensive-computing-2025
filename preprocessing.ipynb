{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "ab607e637582a9b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T14:36:54.182542Z",
     "start_time": "2025-04-14T14:36:50.437957Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:36:55.241212Z",
     "start_time": "2025-04-14T14:36:54.201952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_json('Assignment_1_Assets/reviews_devset.json', lines=True)\n",
    "df.head()"
   ],
   "id": "b0e06bf9a336ae5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0  A2VNYWOPJ13AFP  0981850006    Amazon Customer \"carringt0n\"  [6, 7]   \n",
       "1  A2E5XXXC07AGA7  B00002N66D                           James  [1, 1]   \n",
       "2  A16PX63WZIEQ13  B00002N67U                         Finaldx  [0, 1]   \n",
       "3  A2OSWM3522VARA  B00002N6AN  Wayne Allen \"Motoring Patriot\"  [0, 0]   \n",
       "4  A2SX9YPPGEUADI  B00002N8K3   HappyCamper \"Happy Housewife\"  [4, 5]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This was a gift for my other husband.  He's ma...        5   \n",
       "1  This is a very nice spreader.  It feels very s...        5   \n",
       "2  The metal base with the hose attachments is ve...        1   \n",
       "3  For the most part this works pretty good. I bo...        4   \n",
       "4  This hose is supposed to be flexible.  Its har...        1   \n",
       "\n",
       "               summary  unixReviewTime   reviewTime              category  \n",
       "0               Delish      1259798400   12 3, 2009  Patio_Lawn_and_Garde  \n",
       "1        Nice spreader      1354492800   12 3, 2012  Patio_Lawn_and_Garde  \n",
       "2  Terrible spike base      1218585600  08 13, 2008  Patio_Lawn_and_Garde  \n",
       "3    gets the job done      1254355200   10 1, 2009  Patio_Lawn_and_Garde  \n",
       "4            The worst      1373673600  07 13, 2013  Patio_Lawn_and_Garde  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VNYWOPJ13AFP</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>Amazon Customer \"carringt0n\"</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>This was a gift for my other husband.  He's ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>Delish</td>\n",
       "      <td>1259798400</td>\n",
       "      <td>12 3, 2009</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2E5XXXC07AGA7</td>\n",
       "      <td>B00002N66D</td>\n",
       "      <td>James</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is a very nice spreader.  It feels very s...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice spreader</td>\n",
       "      <td>1354492800</td>\n",
       "      <td>12 3, 2012</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A16PX63WZIEQ13</td>\n",
       "      <td>B00002N67U</td>\n",
       "      <td>Finaldx</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>The metal base with the hose attachments is ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible spike base</td>\n",
       "      <td>1218585600</td>\n",
       "      <td>08 13, 2008</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2OSWM3522VARA</td>\n",
       "      <td>B00002N6AN</td>\n",
       "      <td>Wayne Allen \"Motoring Patriot\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>For the most part this works pretty good. I bo...</td>\n",
       "      <td>4</td>\n",
       "      <td>gets the job done</td>\n",
       "      <td>1254355200</td>\n",
       "      <td>10 1, 2009</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2SX9YPPGEUADI</td>\n",
       "      <td>B00002N8K3</td>\n",
       "      <td>HappyCamper \"Happy Housewife\"</td>\n",
       "      <td>[4, 5]</td>\n",
       "      <td>This hose is supposed to be flexible.  Its har...</td>\n",
       "      <td>1</td>\n",
       "      <td>The worst</td>\n",
       "      <td>1373673600</td>\n",
       "      <td>07 13, 2013</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can observe the following columns and content:\n",
    "* reviewerID - string - the ID of the author of the review\n",
    "* asin - string - unique product identifier\n",
    "* reviewerName - string - name of the reviewer\n",
    "* helpful - array of two integers [a,b] - helpfulness rating of the review: a out of b customers found the review helpful\n",
    "* reviewText - string - the content of the review; this is the text to be processed\n",
    "* overall - float - rating given to product asin by reviewer reviewerID\n",
    "* summary - string - the title of the review\n",
    "* unixReviewTime - integer - timestamp of when review was created in UNIX format\n",
    "* reviewTime - string - date when review was created in human readable format\n",
    "* category - string - the category that the product belongs to\n"
   ],
   "id": "485935c4deba8348"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tokenization\n",
    "Now, we will tokenize all words using the following delimiters:\n",
    "* whitespaces\n",
    "* tabs\n",
    "* digits\n",
    "* characters ()[]{}.!?,;:+=-_\"'`~#@&*%€$§\\/\n",
    "\n",
    "We will use a function that loops thorugh the content and tokenizes each word and put it to lowercase.."
   ],
   "id": "db79af316f2c6695"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:36:58.687767Z",
     "start_time": "2025-04-14T14:36:55.296705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_tokenized = df.copy()\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    # This pattern:\n",
    "    # 1. Uses word boundaries to prevent first-letter cuts\n",
    "    # 2. Still splits on all specified delimiters including - and _\n",
    "    # 3. Handles punctuation correctly\n",
    "    tokens = re.findall(r\"\\b[\\w']+(?:-[\\w']+)*\\b\", str(text).lower())\n",
    "    return [token for token in tokens if token]\n",
    "\n",
    "# Tokenize text columns\n",
    "text_columns = ['reviewText', 'summary']\n",
    "for col in text_columns:\n",
    "    df_tokenized[col+'_tokens'] = df[col].apply(tokenize_text)"
   ],
   "id": "4259d924f8bdde2c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:36:58.958578Z",
     "start_time": "2025-04-14T14:36:58.939722Z"
    }
   },
   "cell_type": "code",
   "source": "df_tokenized.head(2)",
   "id": "d750720dcd29ec68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       reviewerID        asin                  reviewerName helpful  \\\n",
       "0  A2VNYWOPJ13AFP  0981850006  Amazon Customer \"carringt0n\"  [6, 7]   \n",
       "1  A2E5XXXC07AGA7  B00002N66D                         James  [1, 1]   \n",
       "\n",
       "                                          reviewText  overall        summary  \\\n",
       "0  This was a gift for my other husband.  He's ma...        5         Delish   \n",
       "1  This is a very nice spreader.  It feels very s...        5  Nice spreader   \n",
       "\n",
       "   unixReviewTime  reviewTime              category  \\\n",
       "0      1259798400  12 3, 2009  Patio_Lawn_and_Garde   \n",
       "1      1354492800  12 3, 2012  Patio_Lawn_and_Garde   \n",
       "\n",
       "                                   reviewText_tokens    summary_tokens  \n",
       "0  [this, was, a, gift, for, my, other, husband, ...          [delish]  \n",
       "1  [this, is, a, very, nice, spreader, it, feels,...  [nice, spreader]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>category</th>\n",
       "      <th>reviewText_tokens</th>\n",
       "      <th>summary_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2VNYWOPJ13AFP</td>\n",
       "      <td>0981850006</td>\n",
       "      <td>Amazon Customer \"carringt0n\"</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>This was a gift for my other husband.  He's ma...</td>\n",
       "      <td>5</td>\n",
       "      <td>Delish</td>\n",
       "      <td>1259798400</td>\n",
       "      <td>12 3, 2009</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "      <td>[this, was, a, gift, for, my, other, husband, ...</td>\n",
       "      <td>[delish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2E5XXXC07AGA7</td>\n",
       "      <td>B00002N66D</td>\n",
       "      <td>James</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This is a very nice spreader.  It feels very s...</td>\n",
       "      <td>5</td>\n",
       "      <td>Nice spreader</td>\n",
       "      <td>1354492800</td>\n",
       "      <td>12 3, 2012</td>\n",
       "      <td>Patio_Lawn_and_Garde</td>\n",
       "      <td>[this, is, a, very, nice, spreader, it, feels,...</td>\n",
       "      <td>[nice, spreader]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Stopwords filtering\n",
    "\n",
    "Now, we will filter out stopwords that are contained in the stopwords.txt file. Further, we will filter out all tokens consisting of one character."
   ],
   "id": "6367dbd53afafc21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T14:37:03.619351Z",
     "start_time": "2025-04-14T14:36:59.110949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_tokenized = df.copy()\n",
    "\n",
    "# Load stopwords\n",
    "with open('Assignment_1_Assets/stopwords.txt', 'r') as f:\n",
    "    stopwords = set(line.strip() for line in f)\n",
    "\n",
    "# Improved tokenization function with filtering\n",
    "def tokenize_and_filter(text):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "\n",
    "    # 1. Define the exact delimiter characters provided\n",
    "    #    We need to escape special regex characters like ., +, *, ?, ^, $, (, ), [, ], {, }, | \\\n",
    "    delimiter_chars = r'()\\[\\]{}.!?,;:+=\\-_\"\\'`~#@&*%€$§\\\\/' # Note the double backslash for literal \\\n",
    "\n",
    "    # 2. Create the regex pattern:\n",
    "    #    - Match one or more whitespace characters (\\s+)\n",
    "    #    - OR (|)\n",
    "    #    - Match one or more digit characters (\\d+)\n",
    "    #    - OR (|)\n",
    "    #    - Match one or more of the specified delimiter characters ([delimiter_chars]+)\n",
    "    #    We group them to split on any sequence of these.\n",
    "    split_pattern = rf'[\\s\\d{re.escape(delimiter_chars)}]+' # Use re.escape for safety\n",
    "\n",
    "    # 3. Split the lowercase text using the pattern\n",
    "    #    re.split can produce empty strings if delimiters are at the start/end\n",
    "    #    or if multiple delimiters are adjacent.\n",
    "    tokens = re.split(split_pattern, str(text).lower())\n",
    "\n",
    "    # 4. Filter out empty strings, stopwords, and single-character tokens\n",
    "    filtered_tokens = [\n",
    "        token for token in tokens\n",
    "        if token                                # Ensure token is not an empty string\n",
    "           and token not in stopwords\n",
    "           and len(token) > 1\n",
    "    ]\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "# Apply to text columns\n",
    "text_columns = ['reviewText', 'summary']\n",
    "for col in text_columns:\n",
    "    # Add a check if the column exists before applying\n",
    "    if col in df.columns:\n",
    "        df_tokenized[col+'_tokens'] = df[col].apply(tokenize_and_filter)\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found in DataFrame.\")"
   ],
   "id": "5c03b768e920afa2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T15:45:10.832936Z",
     "start_time": "2025-04-14T15:45:09.195028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df_tokenized.head(2))\n",
    "dataframe_preprocessed = df_tokenized.copy()\n",
    "dataframe_preprocessed.to_csv('chi_input.csv', index=False, columns = ['reviewText_tokens', 'category'])"
   ],
   "id": "5ff10dc2d97fe549",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin                  reviewerName helpful  \\\n",
      "0  A2VNYWOPJ13AFP  0981850006  Amazon Customer \"carringt0n\"  [6, 7]   \n",
      "1  A2E5XXXC07AGA7  B00002N66D                         James  [1, 1]   \n",
      "\n",
      "                                          reviewText  overall        summary  \\\n",
      "0  This was a gift for my other husband.  He's ma...        5         Delish   \n",
      "1  This is a very nice spreader.  It feels very s...        5  Nice spreader   \n",
      "\n",
      "   unixReviewTime  reviewTime              category  \\\n",
      "0      1259798400  12 3, 2009  Patio_Lawn_and_Garde   \n",
      "1      1354492800  12 3, 2012  Patio_Lawn_and_Garde   \n",
      "\n",
      "                                   reviewText_tokens    summary_tokens  \n",
      "0  [gift, husband, making, things, time, love, fo...          [delish]  \n",
      "1  [nice, spreader, feels, solid, pneumatic, tire...  [nice, spreader]  \n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
