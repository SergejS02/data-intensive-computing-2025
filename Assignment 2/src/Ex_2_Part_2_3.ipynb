{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f400a1-9cf2-4303-9cea-6cf1d2806180",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a73033a-7a16-47d5-82bf-1c3a0a551557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/13 00:48:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/13 00:48:48 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/05/13 00:48:50 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#open spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"A2-Part2-Pipeline\").getOrCreate()\n",
    "\n",
    "#load reviews and stopwords\n",
    "DEBUG = True\n",
    "if DEBUG:\n",
    "    RAW_PATH = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviews_devset.json\"\n",
    "else:\n",
    "    RAW_PATH = \"hdfs:///user/dic25_shared/amazon-reviews/full/reviewscombined.json\"\n",
    "stopwordsPath = \"Exercise_1/stopwords.txt\"\n",
    "#define structure of json for faster reading\n",
    "from pyspark.sql import types as T\n",
    "review_schema = T.StructType([\n",
    "     T.StructField(\"reviewerID\",      T.StringType(),  True),\n",
    "     T.StructField(\"asin\",            T.StringType(),  True),\n",
    "     T.StructField(\"reviewerName\",    T.StringType(),  True),\n",
    "     T.StructField(\"helpful\",         T.ArrayType(T.IntegerType()), True),\n",
    "     T.StructField(\"reviewText\",      T.StringType(),  True),\n",
    "     T.StructField(\"overall\",         T.FloatType(),   True),\n",
    "     T.StructField(\"summary\",         T.StringType(),  True),\n",
    "     T.StructField(\"unixReviewTime\",  T.LongType(),    True),\n",
    "     T.StructField(\"reviewTime\",      T.StringType(),  True),\n",
    "     T.StructField(\"category\",        T.StringType(),  True),\n",
    " ])\n",
    "#read and select category and review\n",
    "df = (\n",
    "    spark.read\n",
    "         .schema(review_schema)\n",
    "         .json(RAW_PATH)\n",
    "         .selectExpr(\"reviewText AS text\",\n",
    "                     \"category\")\n",
    "    .na.drop(subset=[\"text\", \"category\"])\n",
    ")\n",
    "\n",
    "# reading the stopwords\n",
    "stopwords = spark.sparkContext.textFile(stopwordsPath).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54af8e1-0dd3-4ae0-a6ea-b620812dafaf",
   "metadata": {},
   "source": [
    "Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03933214-ef07-42a7-a80e-0759ec54b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    RegexTokenizer,\n",
    "    StopWordsRemover,\n",
    "    CountVectorizer,\n",
    "    IDF,\n",
    "    ChiSqSelector,\n",
    "    StringIndexer\n",
    ")\n",
    "\n",
    "# 1 Tokenisation and lower-casing via RegexTokenizer\n",
    "tokenizer = RegexTokenizer(\n",
    "    inputCol=\"text\",\n",
    "    outputCol=\"tokens\",\n",
    "    pattern=r\"\"\"[ \\t0-9()\\[\\]{}.!?,;:+=\\-_\"'`~#@&*%â‚¬$Â§\\\\/]+\"\"\",  # delimiters\n",
    "    gaps=True,                # pattern defines the split points\n",
    "    toLowercase=True,\n",
    ")\n",
    "\n",
    "# 2 Stopword removal\n",
    "stopper = StopWordsRemover(inputCol=\"tokens\",stopWords = stopwords, outputCol=\"clean_tokens\")\n",
    "\n",
    "\n",
    "# 3 Vectorizing\n",
    "cv = CountVectorizer(\n",
    "    inputCol=\"clean_tokens\",\n",
    "    outputCol=\"tf\",\n",
    "    minDF=2,\n",
    "    vocabSize=50_000, \n",
    ")\n",
    "\n",
    "# 4 IDF weighting\n",
    "idf = IDF(inputCol=\"tf\", outputCol=\"tfidf\")\n",
    "\n",
    "# 5 encode the category column from string to int\n",
    "encoder = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "\n",
    "# 6 select top 2000 terms by chiÂ²\n",
    "selector = ChiSqSelector(\n",
    "    numTopFeatures=2000,\n",
    "    featuresCol=\"tfidf\",\n",
    "    outputCol=\"chi2_features\",\n",
    "    labelCol=\"label\",\n",
    ")\n",
    "\n",
    "# 7 Pipeline assembly\n",
    "pipeline = Pipeline(stages=[tokenizer, stopper, cv, idf, encoder, selector])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594a4d69-244a-4402-b584-c5c7f00213e3",
   "metadata": {},
   "source": [
    "Fit pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63afc1c-cc8c-4d1b-a256-f9fc003c8127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/13 00:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1243.4 KiB\n",
      "25/05/13 00:50:07 WARN DAGScheduler: Broadcasting large task binary with size 1245.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/05/13 00:50:16 WARN DAGScheduler: Broadcasting large task binary with size 1247.5 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Fit pipeline\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"128\")\n",
    "df.persist() # persisting intermediate output, better for large datasets\n",
    "model = pipeline.fit(df)\n",
    "df.unpersist()\n",
    "\n",
    "# Extract vocabulary & selected indices\n",
    "vocab = model.stages[2].vocabulary                        # get vocabulary from Vecorizer\n",
    "selected = model.stages[-1].selectedFeatures             # index of term after selector\n",
    "\n",
    "selected_terms = [vocab[i] for i in selected]            # map indices to terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c442d23-66d0-438b-b187-297331c4e35b",
   "metadata": {},
   "source": [
    "Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e30e7ae-6cac-4a34-be9b-093766dbd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2000 terms to /home/e12427512/Exercise_2/src/output_ds.txt\n"
     ]
    }
   ],
   "source": [
    "# Saves top 2000 terms to output_ds.txt (one term per line)\n",
    "import pathlib, os, codecs\n",
    "\n",
    "out_file = pathlib.Path(\"output_ds.txt\")\n",
    "out_file.write_text(\"\\n\".join(selected_terms), encoding=\"utf-8\")\n",
    "print(f\"Wrote {len(selected_terms)} terms to {out_file.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "071a1f36-be16-4fab-9cfd-bee01ac49f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Optional: automatic comparison with Assignment 1\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# old_terms = pathlib.Path(\"assignment1_terms.txt\").read_text(encoding=\"utf-8\").splitlines()\n",
    "# old_set, new_set = set(old_terms), set(selected_terms)\n",
    "# print(\"\\nðŸ”¹  Terms kept in *both* assignments:\", len(old_set & new_set))\n",
    "# print(\"ðŸ”¸  Terms only in Assignment 1:\",      len(old_set - new_set))\n",
    "# print(\"ðŸ”¸  Terms only in Spark pipeline:\",    len(new_set - old_set))\n",
    "# (You can also diff the two files directly with any text-diff tool.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be9d159b-bed8-4bc7-b7ee-a7902483fd2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Exercise_1/src/output_dev.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Read the file and get the last line (merged vocabulary)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lines \u001b[38;5;241m=\u001b[39m \u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../Exercise_1/src/output_dev.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m      3\u001b[0m merged_vocab_line \u001b[38;5;241m=\u001b[39m lines[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# This is the merged vocab line\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Split merged vocab into terms\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1266\u001b[0m, in \u001b[0;36mPath.read_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;124;03m    Open the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1252\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, buffering\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1247\u001b[0m          errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;124;03m    Open the file pointed by this path and return a file object, as\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;124;03m    the built-in open() function does.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/pathlib.py:1120\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Exercise_1/src/output_dev.txt'"
     ]
    }
   ],
   "source": [
    "# Step 1: Read the file and get the last line (merged vocabulary)\n",
    "lines = pathlib.Path(\"../Exercise_1/src/output_dev.txt\").read_text(encoding=\"utf-8\").splitlines()\n",
    "merged_vocab_line = lines[-1]  # This is the merged vocab line\n",
    "\n",
    "# Step 2: Split merged vocab into terms\n",
    "old_terms = merged_vocab_line.strip().split()\n",
    "old_set = set(old_terms)\n",
    "\n",
    "# Step 3: Load selected terms from Spark pipeline (output_ds.txt)\n",
    "new_terms = pathlib.Path(\"output_ds.txt\").read_text(encoding=\"utf-8\").splitlines()\n",
    "new_set = set(term.strip() for term in new_terms)\n",
    "\n",
    "# Step 4: Compare sets\n",
    "common_terms = old_set & new_set\n",
    "only_in_old = old_set - new_set\n",
    "only_in_new = new_set - old_set\n",
    "\n",
    "# Step 5: Print results\n",
    "print(f\"Terms in BOTH assignments: {len(common_terms)}\")\n",
    "print(f\"Terms ONLY in Assignment 1: {len(only_in_old)}\")\n",
    "print(f\"Terms ONLY in Spark pipeline (Assignment 2): {len(only_in_new)}\")\n",
    "print(f\"Overlap: {len(common_terms) / len(new_set) * 100:.2f}% of Spark-selected terms are also in Assignment 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a22937-d901-4d24-80e1-bd48d09ea236",
   "metadata": {},
   "source": [
    "# Part 3 \n",
    "// Not working yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59f7bd03-d489-4209-853b-bf27a441d887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[label: double, chi2_features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_3 = model.transform(df).select(\"label\",\"chi2_features\").toDF(\"label\",\"chi2_features\")\n",
    "display(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6b4f073-a26d-4413-8c2e-66f29451a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.classification import LinearSVC,  OneVsRest\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.ml.feature import (Tokenizer, StopWordsRemover, \n",
    "                               CountVectorizer, IDF, \n",
    "                               ChiSqSelector, Normalizer, \n",
    "                               StringIndexer)\n",
    "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")   # WARN-Meldungen verschwinden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5697adc-aa95-4ad0-9195-473f311bdeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Complete Text Processing Pipeline\n",
    "\n",
    "# 1. Convert category to numeric index\n",
    "label_indexer = StringIndexer(inputCol=\"category\", outputCol=\"label_index\")\n",
    "\n",
    "# 2. Text processing pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "stopper = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\")\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"tfidf_features\")\n",
    "selector = ChiSqSelector(featuresCol=\"tfidf_features\", \n",
    "                       outputCol=\"selected_features\",\n",
    "                       labelCol=\"label_index\",\n",
    "                       numTopFeatures=2000)\n",
    "selector_heavy = ChiSqSelector(featuresCol=\"tfidf_features\",\n",
    "                             outputCol=\"selected_features_heavy\",\n",
    "                             labelCol=\"label_index\",\n",
    "                             numTopFeatures=500)  # Heavy filtering\n",
    "normalizer = Normalizer(inputCol=\"selected_features\", \n",
    "                      outputCol=\"scaled_features\",\n",
    "                      p=2.0)\n",
    "\n",
    "# 3. Classifier setup\n",
    "binary_svm = LinearSVC(featuresCol=\"scaled_features\",\n",
    "                     labelCol=\"label_index\",\n",
    "                     maxIter=50,\n",
    "                     regParam=0.1)\n",
    "\n",
    "ovr = OneVsRest(classifier=binary_svm,\n",
    "              featuresCol=\"scaled_features\",\n",
    "              labelCol=\"label_index\")\n",
    "\n",
    "# 4. Full pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    label_indexer,\n",
    "    tokenizer,\n",
    "    stopper,\n",
    "    cv,\n",
    "    idf,\n",
    "    selector,\n",
    "    normalizer,\n",
    "    ovr\n",
    "])\n",
    "\n",
    "full_param_grid = (ParamGridBuilder()\n",
    "    .addGrid(selector.numTopFeatures, [500, 2000])  # Compare feature sizes\n",
    "    .addGrid(binary_svm.regParam, [0.01, 0.1, 1.0])\n",
    "    .addGrid(binary_svm.standardization, [True, False])\n",
    "    .addGrid(binary_svm.maxIter, [10, 50])\n",
    "    .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88231142-e17a-42d9-9fe6-a48eb7476f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 47490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 15664\n",
      "\n",
      "Running cross-validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 853\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Execute the pipeline\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mrun_full_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m, in \u001b[0;36mrun_full_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning cross-validation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m cv_model \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m best_model \u001b[38;5;241m=\u001b[39m cv_model\u001b[38;5;241m.\u001b[39mbestModel\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/tuning.py:847\u001b[0m, in \u001b[0;36mCrossValidator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    841\u001b[0m train \u001b[38;5;241m=\u001b[39m datasets[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcache()\n\u001b[1;32m    843\u001b[0m tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    844\u001b[0m     inheritable_thread_target,\n\u001b[1;32m    845\u001b[0m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam),\n\u001b[1;32m    846\u001b[0m )\n\u001b[0;32m--> 847\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, metric, subModel \u001b[38;5;129;01min\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mimap_unordered(\u001b[38;5;28;01mlambda\u001b[39;00m f: f(), tasks):\n\u001b[1;32m    848\u001b[0m     metrics_all[i][j] \u001b[38;5;241m=\u001b[39m metric\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m collectSubModelsParam:\n",
      "File \u001b[0;32m/usr/lib64/python3.9/multiprocessing/pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    860\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/usr/lib64/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Complete Training Function with Cross-Validation\n",
    "def run_full_pipeline():\n",
    "    try:\n",
    "        # Split data\n",
    "        train_val, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "        train, val = train_val.randomSplit([0.75, 0.25], seed=42)  # 60/20/20 split\n",
    "        \n",
    "        print(f\"Training samples: {train.count()}\")\n",
    "        print(f\"Test samples: {test.count()}\")\n",
    "        \n",
    "        # Define evaluator FIRST\n",
    "        evaluator = MulticlassClassificationEvaluator(\n",
    "            labelCol=\"label_index\",\n",
    "            predictionCol=\"prediction\",\n",
    "            metricName=\"f1\"\n",
    "        )\n",
    "        \n",
    "        # Setup CrossValidator\n",
    "        cv = CrossValidator(\n",
    "            estimator=pipeline,\n",
    "            estimatorParamMaps=full_param_grid,\n",
    "            evaluator=evaluator,\n",
    "            numFolds=3,\n",
    "            parallelism=4,\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        print(\"\\nRunning cross-validation...\")\n",
    "        cv_model = cv.fit(train)\n",
    "        best_model = cv_model.bestModel\n",
    "        \n",
    "        # Evaluate\n",
    "        predictions = best_model.transform(test)\n",
    "        \n",
    "        print(\"\\nBest Model Parameters:\")\n",
    "        print(f\"regParam: {best_model.stages[-1].getClassifier().getRegParam()}\")\n",
    "        print(f\"maxIter: {best_model.stages[-1].getClassifier().getMaxIter()}\")\n",
    "        print(f\"standardization: {best_model.stages[-1].getClassifier().getStandardization()}\")\n",
    "        \n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        print(f\"{'F1 Score':>12}: {evaluator.evaluate(predictions):.4f}\")\n",
    "        print(f\"{'Accuracy':>12}: {evaluator.setMetricName('accuracy').evaluate(predictions):.4f}\")\n",
    "        \n",
    "        # Show predictions with original labels\n",
    "        label_map = {i:l for i,l in enumerate(best_model.stages[0].labels)}\n",
    "        predictions = predictions.withColumn(\n",
    "            \"predicted_category\",\n",
    "            udf(lambda x: label_map[x], StringType())(\"prediction\")\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSample Predictions:\")\n",
    "        predictions.select(\"category\", \"predicted_category\").show(10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during training: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Execute the pipeline\n",
    "run_full_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd8db3-03d4-418c-aaf0-4e8c74157403",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deba7cd8-cdd7-4308-8c88-b729445e8135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
